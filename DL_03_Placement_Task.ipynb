{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDcnQejhBAO43O7u8eL6GK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran0897/Placement-Assignment_Md_Imran/blob/main/DL_03_Placement_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow Implementation:"
      ],
      "metadata": {
        "id": "bn0l7aUBIriK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((-1, 28, 28, 1)).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape((-1, 28, 28, 1)).astype(\"float32\") / 255.0\n",
        "\n",
        "# Define the Pure CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(8, (5, 5), padding=\"same\", activation=\"relu\", input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(4, 4),\n",
        "    Conv2D(12, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "    Flatten(),\n",
        "    Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "min_val_accuracy = 99.4\n",
        "best_model_path = \"best_model.h5\"\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, verbose=1, mode=\"max\")\n",
        "\n",
        "model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Save the best model based on validation accuracy\n",
        "model.save(best_model_path)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8of_1Ye0IsUN",
        "outputId": "a8044793-65cf-4653-d723-23905015617b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 8)         208       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 7, 7, 8)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 7, 7, 12)          2412      \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 588)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5890      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,510\n",
            "Trainable params: 8,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "844/844 [==============================] - 34s 40ms/step - loss: 0.3387 - accuracy: 0.9040 - val_loss: 0.0982 - val_accuracy: 0.9737\n",
            "Epoch 2/10\n",
            "844/844 [==============================] - 31s 37ms/step - loss: 0.1005 - accuracy: 0.9704 - val_loss: 0.0671 - val_accuracy: 0.9840\n",
            "Epoch 3/10\n",
            "844/844 [==============================] - 33s 39ms/step - loss: 0.0725 - accuracy: 0.9785 - val_loss: 0.0613 - val_accuracy: 0.9838\n",
            "Epoch 4/10\n",
            "844/844 [==============================] - 31s 37ms/step - loss: 0.0607 - accuracy: 0.9820 - val_loss: 0.0618 - val_accuracy: 0.9825\n",
            "Epoch 5/10\n",
            "844/844 [==============================] - 34s 40ms/step - loss: 0.0518 - accuracy: 0.9842 - val_loss: 0.0483 - val_accuracy: 0.9865\n",
            "Epoch 6/10\n",
            "844/844 [==============================] - 32s 38ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0488 - val_accuracy: 0.9867\n",
            "Epoch 7/10\n",
            "844/844 [==============================] - 31s 37ms/step - loss: 0.0407 - accuracy: 0.9871 - val_loss: 0.0398 - val_accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "844/844 [==============================] - 33s 39ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.0411 - val_accuracy: 0.9888\n",
            "Epoch 9/10\n",
            "844/844 [==============================] - 31s 37ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.0377 - val_accuracy: 0.9897\n",
            "Epoch 10/10\n",
            "844/844 [==============================] - 33s 39ms/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 0.0381 - val_accuracy: 0.9898\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0366 - accuracy: 0.9888\n",
            "Test Accuracy: 98.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Implementation:"
      ],
      "metadata": {
        "id": "3dp-JabjKpyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "# Set device configuration (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the Pure CNN model\n",
        "class PureCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PureCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(8, 12, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(12, 16, 3, padding=1)\n",
        "        self.fc = nn.Linear(16 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = x.view(-1, 16 * 7 * 7)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Create the Pure CNN model\n",
        "model = PureCNN().to(device)\n",
        "\n",
        "# Print the model summary\n",
        "summary(model, input_size=(1, 28, 28))\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "min_val_accuracy = 99.4\n",
        "best_model_path = \"best_model.pth\"\n",
        "best_val_accuracy = 0.0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        train_accuracy += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_accuracy /= len(train_loader.dataset)\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    model.eval()\n",
        "    val_accuracy = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_accuracy += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
        "\n",
        "    val_accuracy /= len(test_loader.dataset)\n",
        "\n",
        "    # Save the model with the best validation accuracy\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Stop training if the desired validation accuracy is reached\n",
        "    if val_accuracy >= min_val_accuracy:\n",
        "        print(\"Desired validation accuracy reached. Training stopped.\")\n",
        "        break\n",
        "\n",
        "# Load the best model and evaluate it on the test set\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()\n",
        "\n",
        "test_accuracy = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        test_accuracy += calculate_accuracy(outputs, labels) * inputs.size(0)\n",
        "\n",
        "test_accuracy /= len(test_loader.dataset)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZQEBzvVLIXW",
        "outputId": "329e3b96-7593-4776-f6ec-dcc6a96ddf4f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "         MaxPool2d-2            [-1, 8, 14, 14]               0\n",
            "            Conv2d-3           [-1, 12, 14, 14]             876\n",
            "         MaxPool2d-4             [-1, 12, 7, 7]               0\n",
            "            Conv2d-5             [-1, 16, 7, 7]           1,744\n",
            "            Linear-6                   [-1, 10]           7,850\n",
            "================================================================\n",
            "Total params: 10,550\n",
            "Trainable params: 10,550\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.09\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.13\n",
            "----------------------------------------------------------------\n",
            "Epoch [1/10] - Train Loss: 0.3396, Train Accuracy: 89.74%, Validation Accuracy: 96.73%\n",
            "Epoch [2/10] - Train Loss: 0.0905, Train Accuracy: 97.28%, Validation Accuracy: 98.18%\n",
            "Epoch [3/10] - Train Loss: 0.0634, Train Accuracy: 98.05%, Validation Accuracy: 98.10%\n",
            "Epoch [4/10] - Train Loss: 0.0526, Train Accuracy: 98.36%, Validation Accuracy: 98.33%\n",
            "Epoch [5/10] - Train Loss: 0.0442, Train Accuracy: 98.63%, Validation Accuracy: 98.87%\n",
            "Epoch [6/10] - Train Loss: 0.0390, Train Accuracy: 98.77%, Validation Accuracy: 98.72%\n",
            "Epoch [7/10] - Train Loss: 0.0339, Train Accuracy: 98.93%, Validation Accuracy: 98.79%\n",
            "Epoch [8/10] - Train Loss: 0.0300, Train Accuracy: 99.07%, Validation Accuracy: 98.97%\n",
            "Epoch [9/10] - Train Loss: 0.0271, Train Accuracy: 99.15%, Validation Accuracy: 98.79%\n",
            "Epoch [10/10] - Train Loss: 0.0251, Train Accuracy: 99.17%, Validation Accuracy: 98.93%\n",
            "Test Accuracy: 98.97%\n"
          ]
        }
      ]
    }
  ]
}