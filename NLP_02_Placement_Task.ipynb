{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WT2QrSrfBI7os5rXpHpeJzqp-0ebzvZ6",
      "authorship_tag": "ABX9TyM3IMFDeWfPYASfdozl0naC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran0897/Placement-Assignment_Md_Imran/blob/main/NLP_02_Placement_Task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ-m7QYFy5eN",
        "outputId": "9a615e5a-361e-4f25-a46a-1ed6744adc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import csv\n",
        "from collections import Counter\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cVT_UjA-z3bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the PDF file in read binary mode\n",
        "pdf_file = open('/content/drive/MyDrive/Placement_Task/NLP_02/Data Science.pdf', 'rb')  # Replace 'example.pdf' with your PDF file path"
      ],
      "metadata": {
        "id": "R7POZh9qz5P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PDF reader object\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)"
      ],
      "metadata": {
        "id": "V1Boupy5z76B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from each page of the PDF\n",
        "text = \"\"\n",
        "for page in pdf_reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "# Close the PDF file\n",
        "pdf_file.close()"
      ],
      "metadata": {
        "id": "BEdxagBL0Q44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the extracted text in a CSV file\n",
        "csv_file = 'extracted_text.csv'"
      ],
      "metadata": {
        "id": "aREd3CM_0WF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Text'])\n",
        "    writer.writerow([text])"
      ],
      "metadata": {
        "id": "84QtTX1w0WJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('/content/drive/MyDrive/Placement_Task/NLP_03/extracted_text.csv')['Text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "GaK8DwR24-jg",
        "outputId": "b3138b6a-152c-4db2-85ed-45f5addb8fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Python\\nT o t a l\\nM a r k s :\\n1 0 0\\nE a c h\\nq u e s t i o n\\n1 0\\nm a r k s\\nQuestion1:-\\nWriteaprogramthattakesastringasinput,andcountsthefrequencyofeachwordinthestring,theremightberepeatedcharactersinthestring.Yourtaskistofindthehighestfrequencyandreturnsthelengthofthehighest-frequencyword.\\nNote-Youhavetowriteatleast2additionaltestcasesinwhichyourprogramwillrunsuccessfullyandprovideanexplanationforthesame.\\nExampleinput-string=‚Äúwritewritewriteallthenumberfromfromfrom1to100‚Äù\\nExampleoutput-5\\nExplanation-Fromthegivenstringwecannotethatthemostfrequentwordsare‚Äúwrite‚Äùand‚Äúfrom‚Äùandthemaximumvalueofboththevaluesis‚Äúwrite‚Äùanditscorrespondinglengthis5\\nQuestion2:-\\nConsiderastringtobevalidifallcharactersofthestringappearthesamenumberoftimes.Itisalsovalidifhecanremovejustonecharacterattheindexinthestring,andtheremainingcharacterswilloccurthesame\\nnumberoftimes.Givenastring,determineifitisvalid.Ifso,return\\nYES,otherwisereturn\\nNO.\\nNote-Youhavetowriteatleast2additionaltestcasesinwhichyourprogramwillrunsuccessfullyandprovideanexplanationforthesame.\\nExampleinput1-s=‚Äúabc‚Äù.Thisisavalidstringbecausefrequenciesare{‚Äúa‚Äù:1,‚Äúb‚Äù:1,‚Äúc‚Äù:1}\\nExampleoutput1-YES\\nExampleinput2-s‚Äúabcc‚Äù.Thisstringisnotvalidaswecanremoveonly1occurrenceof‚Äúc‚Äù.Thatleavescharacterfrequenciesof{‚Äúa‚Äù:1,‚Äúb‚Äù:1,‚Äúc‚Äù:2}\\nExampleoutput2-NO\\nQuestion3:-\\nWriteaprogram,whichwoulddownloadthedatafromtheprovidedlink,andthenreadthedataandconvertthatintoproperlystructureddataandreturnitinExcelformat.\\nNote-Writecommentswherevernecessaryexplainingthecodewritten.Link-https://raw.githubusercontent.com/Biuni/PokemonGO-Pokedex/master/pokedex.json\\nDataAttributes-id:IdentificationNumber-intnum:Numberofthe\\n‚óèPok√©monintheofficialPok√©dex-intname:Pok√©monname-\\n‚óèstringimg:URLtoanimageofthisPok√©mon-stringtype: \\n‚óèPok√©montype-stringheight:Pok√©monheight-float\\n‚óèweight:Pok√©monweight-floatcandy:typeofcandyusedtoevolvePok√©monor\\ngiven\\n‚óèwhentransferred-stringcandy_count:theamountofcandiesrequiredtoevolve\\n-int\\n‚óèegg:Numberofkilometerstotraveltohatchtheegg-floatspawn_chance:\\n‚óèPercentageofspawnchance(NEW)-floatavg_spawns:Numberofthis\\npokemonon10.000spawns(NEW)-int\\n‚óèspawn_time:Spawnsmostactiveatthetimeonthisfield.Spawntimesarethesameforall\\ntimezonesandareexpressedinlocaltime.(NEW)-‚Äúminutes:seconds‚Äùmultipliers:\\nMultiplierofCombatPower(CP)forcalculatingtheCPafterevolutionSeebelow-listofint\\nweakness:Typesof\\n‚óèPok√©monthisPok√©monisweakto-listofstringsnext_evolution:NumberandNameof\\nsuccessiveevolutionsofPok√©mon-listofdictprev_evolution:NumberandNameofprevious\\nevolutionsofPok√©mon--listofdict\\nQuestion4-\\nWriteaprogramtodownloadthedatafromthelinkgivenbelowandthenreadthedataandconverttheintotheproperstructureandreturnitasaCSVfile.\\nLink-https://data.nasa.gov/resource/y77d-th95.json\\nNote-Writecodecommentswhereverneededforcodeunderstanding.SampleData-\\nExceptedOutputDataAttributes\\n‚óèNameofEarthMeteorite-stringid-IDofEarth\\n‚óèMeteorite-intnametype-stringrecclass-string \\n‚óèmass-MassofEarthMeteorite-floatyear-YearatwhichEarth \\n‚óèMeteoritewashit-datetimeformatreclat-floatrecclong-float \\n‚óèpointcoordinates-listofint\\nQuestion5-\\nWriteaprogramtodownloadthedatafromthegivenAPIlinkandthenextractthefollowingdatawithproperformatting\\nLink-http://api.tvmaze.com/singlesearch/shows?q=westworld&embed=episodes\\nNote-Writepropercodecommentswhereverneededforthecodeunderstanding\\nSampleData-\\nExceptedOutputDataAttributes-\\n‚óèid-inturl-string\\n‚óèname-stringseason \\n‚óè-intnumber-int \\n‚óètype-stringairdate- \\n‚óèdateformatairtime- \\n‚óè12-hourtimeformat \\n‚óèruntime-float \\n‚óèaveragerating-float \\n‚óèsummary-string \\n‚óèwithouthtmltags \\n‚óèmediumimagelink-string \\n‚óèOriginalimagelink-string\\nQuestion6-\\nUsingthedatafromQuestion3,writecodetoanalyzethedataandanswerthefollowingquestionsNote1.\\nDrawplotstodemonstratetheanalysisforthefollowingquestionsforbettervisualizations.\\n2.Writecodecommentswhereverrequiredforcodeunderstanding\\nInsightstobedrawn-\\n‚óèGetallPokemonswhosespawnrateislessthan5% \\n‚óèGetallPokemonsthathavelessthan4weaknesses \\n‚óèGetallPokemonsthathavenomultipliersatall \\n‚óèGetallPokemonsthatdonothavemorethan2evolutions \\n‚óèGetallPokemonswhosespawntimeislessthan300seconds.\\nNote-spawntimeformatis\"05:32‚Äù,soassume‚Äúminute:second‚Äùformatandperformtheanalysis.\\n‚óèGetallPokemonwhohavemorethantwotypesofcapabilities\\nQuestion7-\\nUsingthedatafromQuestion4,writecodetoanalyzethedataandanswerthefollowingquestionsNote-\\n1.Drawplotstodemonstratetheanalysisforthefollowingquestionsforbettervisualizations\\n2.Writecodecommentswhereverrequiredforcodeunderstanding\\nInsightstobedrawn-\\n‚óèGetalltheEarthmeteoritesthatfellbeforetheyear2000 \\n‚óèGetalltheearthmeteoritesco-ordinateswhofellbeforetheyear1970 \\n‚óèAssumingthatthemassoftheearthmeteoriteswasinkg,getallthosewhosemasswasmorethan10000kgQuestion8-\\nUsingthedatafromQuestion5,writecodetheanalyzethedataandanswerthefollowingquestionsNote-\\n1.Drawplotstodemonstratetheanalysisforthefollowingquestionsandbettervisualizations\\n2.Writecodecommentswhereverrequiredforcodeunderstanding\\nInsightstobedrawn-\\n‚óèGetalltheoverallratingsforeachseasonandusingplotscomparetheratingsforalltheseasons,likeseason1ratings,season2,andsoon.\\n‚óèGetalltheepisodenames,whoseaverageratingismorethan8foreveryseason \\n‚óèGetalltheepisodenamesthatairedbeforeMay2019 \\n‚óèGettheepisodenamefromeachseasonwiththehighestandlowestrating \\n‚óèGetthesummaryforthemostpopular(ratings)episodeineveryseason\\nQuestion9-\\nWriteaprogramtoreadthedatafromthefollowinglink,performdataanalysisandanswerthefollowingquestions\\nNote-\\n1.Writecodecommentswhereverrequiredforcodeunderstanding\\nLink-https://data.wa.gov/api/views/f6w7-q2d2/rows.csv?accessType=DOWNLOAD\\nInsightstobedrawn-\\n‚óèGetallthecarsandtheirtypesthatdonotqualifyforcleanalternativefuelvehicle \\n‚óèGetallTESLAcarswiththemodelyear,andmodeltypemadeinBothellCity. \\n‚óèGetallthecarsthathaveanelectricrangeofmorethan100,andweremadeafter\\n2015\\n‚óèDrawplotstoshowthedistributionbetweencityandelectricvehicletype\\nQuestion10-\\nWriteaprogramtocountthenumberofverbs,nouns,pronouns,andadjectivesinagivenparticularphraseorparagraph,andreturntheirrespectivecountasadictionary.\\nNote-\\n1.Writecodecommentswhereverrequiredforcode\\n2.Youhavetowriteatleast2additionaltestcasesinwhichyourprogramwillrunsuccessfullyandprovideanexplanationforthesame.ExampleOutput-\\nStatistics\\nT o t a l\\nM a r k s :\\n1 2 0\\nE a c h\\nq u e s t i o n\\n1 0\\nm a r k s\\nQ - 1 .\\nA\\nuniversity\\nwants\\nto\\nunderstand\\nthe\\nrelationship\\nbetween\\nthe\\nSAT\\nscores\\nof\\nits \\napplicants\\nand\\ntheir\\ncollege\\nGPA.\\nThey\\ncollect\\ndata\\non\\n500\\nstudents,\\nincluding\\ntheir\\nSAT\\nscores\\n(out\\nof\\n1600)\\nand\\ntheir\\ncollege\\nGPA\\n(on\\na\\n4.0\\nscale).\\nThey\\nfind\\nthat\\nthe\\ncorrelation\\ncoefficient\\nbetween\\nSAT\\nscores\\nand\\ncollege\\nGPA\\nis\\n0.7.\\nWhat\\ndoes\\nthis\\ncorrelation\\ncoefficient\\nindicate\\nabout\\nthe\\nrelationship\\nbetween\\nSAT\\nscores\\nand\\ncollege\\nGPA?\\nQ - 2 .\\nConsider\\na\\ndataset\\ncontaining\\nthe\\nheights\\n(in\\ncentimeters)\\nof\\n1000\\nindividuals.\\nThe\\nmean\\nheight\\nis\\n170\\ncm\\nwith\\na\\nstandard\\ndeviation\\nof\\n10\\ncm.\\nThe\\ndataset\\nis\\napproximately\\nnormally\\ndistributed,\\nand\\nits\\nskewness\\nis\\napproximately\\nzero.\\nBased\\non\\nthis\\ninformation,\\nanswer\\nthe\\nfollowing\\nquestions:\\na.\\nWhat\\npercentage\\nof\\nindividuals\\nin\\nthe\\ndataset\\nhave\\nheights\\nbetween\\n160\\ncm\\nand\\n180\\ncm?\\nb.\\nIf\\nwe\\nrandomly\\nselect\\n100\\nindividuals\\nfrom\\nthe\\ndataset,\\nwhat\\nis\\nthe\\nprobability \\nthat\\ntheir\\naverage\\nheight\\nis\\ngreater\\nthan\\n175\\ncm?\\nc.\\nAssuming\\nthe\\ndataset\\nfollows\\na\\nnormal\\ndistribution,\\nwhat\\nis\\nthe\\nz-score \\ncorresponding\\nto\\na\\nheight\\nof\\n185\\ncm?\\nd.\\nWe\\nknow\\nthat\\n5%\\nof\\nthe\\ndataset\\nhas\\nheights\\nbelow\\na\\ncertain\\nvalue.\\nWhat\\nis \\nthe\\napproximate\\nheight\\ncorresponding\\nto\\nthis\\nthreshold?\\ne.\\nCalculate\\nthe\\ncoefficient\\nof\\nvariation\\n(CV)\\nfor\\nthe\\ndataset.\\nf.\\nCalculate\\nthe\\nskewness\\nof\\nthe\\ndataset\\nand\\ninterpret\\nthe\\nresult.\\nQ - 3 .\\nConsider\\nthe\\n‚ÄòBlood\\nPressure\\nBefore‚Äô\\nand\\n‚ÄòBlood\\nPressure\\nAfter‚Äô\\ncolumns\\nfrom\\nthe \\ndata\\nand\\ncalculate\\nthe\\nfollowing\\nhttps://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\\na.\\nMeasure\\nthe\\ndispersion\\nin\\nboth\\nand\\ninterpret\\nthe\\nresults. \\nb.\\nCalculate\\nmean\\nand\\n5%\\nconfidence\\ninterval\\nand\\nplot\\nit\\nin\\na\\ngraph\\nc.\\nCalculate\\nthe\\nMean\\nabsolute\\ndeviation\\nand\\nStandard\\ndeviation\\nand\\ninterpret\\nthe\\nresults.\\nd.\\nCalculate\\nthe\\ncorrelation\\ncoefficient\\nand\\ncheck\\nthe\\nsignificance\\nof\\nit\\nat\\n1%\\nlevel\\nof\\nsignificance.\\nQ - 4\\n.\\nA\\ngroup\\nof\\n20\\nfriends\\ndecide\\nto\\nplay\\na\\ngame\\nin\\nwhich\\nthey\\neach\\nwrite\\na\\nnumber\\nbetween\\n1\\nand\\n20\\non\\na\\nslip\\nof\\npaper\\nand\\nput\\nit\\ninto\\na\\nhat.\\nThey\\nthen\\ndraw\\none\\nslip\\nof\\npaper\\nat\\nrandom.\\nWhat\\nis\\nthe\\nprobability\\nthat\\nthe\\nnumber\\non\\nthe\\nslip\\nof\\npaper\\nis\\na\\nperfect\\nsquare\\n(i.e.,\\n1,\\n4,\\n9,\\nor\\n16)?Q - 5\\n.\\nA\\ncertain\\ncity\\nhas\\ntwo\\ntaxi\\ncompanies:\\nCompany\\nA\\nhas\\n80%\\nof\\nthe\\ntaxis\\nand\\nCompany\\nB\\nhas\\n20%\\nof\\nthe\\ntaxis.\\nCompany\\nA\\'s\\ntaxis\\nhave\\na\\n95%\\nsuccess\\nrate\\nfor\\npicking\\nup\\npassengers\\non\\ntime,\\nwhile\\nCompany\\nB\\'s\\ntaxis\\nhave\\na\\n90%\\nsuccess\\nrate.\\nIf\\na\\nrandomly\\nselected\\ntaxi\\nis\\nlate,\\nwhat\\nis\\nthe\\nprobability\\nthat\\nit\\nbelongs\\nto\\nCompany\\nA?\\nQ - 6 .\\nA\\npharmaceutical\\ncompany\\nis\\ndeveloping\\na\\ndrug\\nthat\\nis\\nsupposed\\nto\\nreduce\\nblood\\npressure.\\nThey\\nconduct\\na\\nclinical\\ntrial\\nwith\\n100\\npatients\\nand\\nrecord\\ntheir\\nblood\\npressure\\nbefore\\nand\\nafter\\ntaking\\nthe\\ndrug.\\nThe\\ncompany\\nwants\\nto\\nknow\\nif\\nthe\\nchange\\nin\\nblood\\npressure\\nfollows\\na\\nnormal\\ndistribution.\\nhttps://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp=share_\\nQ - 7 .\\nThe\\nequations\\nof\\ntwo\\nlines\\nof\\nregression,\\nobtained\\nin\\na\\ncorrelation\\nanalysis \\nbetween\\nvariables\\nX\\nand\\nY\\nare\\nas\\nfollows:\\nand\\n.\\n2\\nùëã\\n+\\n3\\n‚àí\\n8\\n=\\n0\\n2\\nùëå\\n+\\nùëã\\n‚àí\\n5\\n=\\n0\\nThe\\nvariance\\nofùëã=4\\nFind\\nthe\\na.\\nVariance\\nof\\nY\\nb.\\nCoefficient\\nof\\ndetermination\\nof\\nC\\nand\\nY\\nc.\\nStandard\\nerror\\nof\\nestimate\\nof\\nX\\non\\nY\\nand\\nof\\nY\\non\\nX.\\nQ - 8 .\\nThe\\nanxiety\\nlevels\\nof\\n10\\nparticipants\\nwere\\nmeasured\\nbefore\\nand\\nafter\\na\\nnew\\ntherapy. \\nThe\\nscores\\nare\\nnot\\nnormally\\ndistributed.\\nUse\\nthe\\nWilcoxon\\nsigned-rank\\ntest\\nto\\ntest\\nwhether\\nthe\\ntherapy\\nhad\\na\\nsignificant\\neffect\\non\\nanxiety\\nlevels.\\nThe\\ndata\\nis\\ngiven\\nbelow:\\nParticipant\\nBefore\\ntherapy\\nAfter\\ntherapy\\nDifferenceQ - 9\\n.\\nGiven\\nthe\\nscore\\nof\\nstudents\\nin\\nmultiple\\nexams\\nTest\\nthe\\nhypothesis\\nthat\\nthe\\nmean\\nscores\\nof\\nall\\nthe\\nstudents\\nare\\nthe\\nsame.\\nIf\\nnot,\\nname\\nthe \\nstudent\\nwith\\nthe\\nhighest\\nscore.\\nQ - 1 0 .\\nA\\nfactory\\nproduces\\nlight\\nbulbs,\\nand\\nthe\\nprobability\\nof\\na\\nbulb\\nbeing\\ndefective\\nis\\n0.05. \\nThe\\nfactory\\nproduces\\na\\nlarge\\nbatch\\nof\\n500\\nlight\\nbulbs.\\na.\\nWhat\\nis\\nthe\\nprobability\\nthat\\nexactly\\n20\\nbulbs\\nare\\ndefective?\\nb.\\nWhat\\nis\\nthe\\nprobability\\nthat\\nat\\nleast\\n10\\nbulbs\\nare\\ndefective?\\nc.\\nWhat\\nis\\nthe\\nprobability\\nthat\\nat\\nmax\\n15\\nbulbs\\nare\\ndefective?\\nd.\\nOn\\naverage,\\nhow\\nmany\\ndefective\\nbulbs\\nwould\\nyou\\nexpect\\nin\\na\\nbatch\\nof\\n500?\\nQ - 1 1\\n.\\nGiven\\nthe\\ndata\\nof\\na\\nfeature\\ncontributing\\nto\\ndifferent\\nclasses\\nhttps://drive.google.com/file/d/1mCjtYHiX--mMUjicuaP2gH3k-SnFxt8Y/view?usp\\n=share_\\na.\\nCheck\\nwhether\\nthe\\ndistribution\\nof\\nall\\nthe\\nclasses\\nare\\nthe\\nsame\\nor\\nnot. \\nb.\\nCheck\\nfor\\nthe\\nequality\\nof\\nvariance/\\nc.\\nWhich\\namount\\nLDA\\nand\\nQDA\\nwould\\nperform\\nbetter\\non\\nthis\\ndata\\nfor\\nclassification\\nand\\nwhy.\\nd.\\nCheck\\nthe\\nequality\\nof\\nmean\\nfor\\nbetween\\nall\\nthe\\nclasses.\\nQ - 1 2 .\\nA\\npharmaceutical\\ncompany\\ndevelops\\na\\nnew\\ndrug\\nand\\nwants\\nto\\ncompare\\nits \\neffectiveness\\nagainst\\na\\nstandard\\ndrug\\nfor\\ntreating\\na\\nparticular\\ncondition.\\nThey\\nconduct\\na\\nstudy\\nwith\\ntwo\\ngroups:\\nGroup\\nA\\nreceives\\nthe\\nnew\\ndrug,\\nand\\nGroup\\nB\\nreceives\\nthe\\nstandard\\ndrug.\\nThe\\ncompany\\nmeasures\\nthe\\nimprovement\\nin\\na\\nspecific\\nsymptom\\nfor\\nboth\\ngroups\\nafter\\na\\n4-week\\ntreatment\\nperiod.\\na.\\nThe\\ncompany\\ncollects\\ndata\\nfrom\\n30\\npatients\\nin\\neach\\ngroup\\nand\\ncalculates\\nthe \\nmean\\nimprovement\\nscore\\nand\\nthe\\nstandard\\ndeviation\\nof\\nimprovement\\nfor\\neach\\ngroup.\\nThe\\nmean\\nimprovement\\nscore\\nfor\\nGroup\\nA\\nis\\n2.5\\nwith\\na\\nstandard\\ndeviation\\nof\\n0.8,\\nwhile\\nthe\\nmean\\nimprovement\\nscore\\nfor\\nGroup\\nB\\nis\\n2.2\\nwith\\na\\nstandard\\ndeviation\\nof\\n0.6.\\nConduct\\na\\nt-test\\nto\\ndetermine\\nif\\nthere\\nis\\na\\nsignificant\\ndifference\\nin\\nthe\\nmean\\nimprovement\\nscores\\nbetween\\nthe\\ntwo\\ngroups.\\nUse\\na\\nsignificance\\nlevel\\nof\\n0.05.\\nb.\\nBased\\non\\nthe\\nt-test\\nresults,\\nstate\\nwhether\\nthe\\nnull\\nhypothesis\\nshould\\nbe \\nrejected\\nor\\nnot.\\nProvide\\na\\nconclusion\\nin\\nthe\\ncontext\\nof\\nthe\\nstudy.\\nMachinelearning\\nT o t a l\\nM a r k s :\\n2 1 0\\nE a c h\\nq u e s t i o n\\n1 5\\nm a r k s\\nINTERMEDIA TEQUESTIONS:\\nQ-1.ImagineyouhaveadatasetwhereyouhavedifferentInstagramfeatureslikeusername,Caption,Hashtag,Followers,Time_Since_posted,andlikes,nowyourtaskistopredictthenumberoflikesandTimeSincepostedandtherestofthefeaturesareyourinputfeatures.NowyouhavetobuildamodelwhichcanpredictthenumberoflikesandTimeSinceposted.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-2.ImagineyouhaveadatasetwhereyouhavedifferentfeatureslikeAge,Gender,Height,Weight,BMI,andBloodPressureandyouhavetoclassifythepeopleintodifferentclasseslikeNormal,Overweight,Obesity,Underweight,andExtremeObesitybyusingany4differentclassificationalgorithms.Nowyouhavetobuildamodelwhichcanclassifypeopleintodifferentclasses.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-3.Imagineyouhaveadatasetwhereyouhavedifferentcategoriesofdata,Nowyouneedtofindthemostsimilardatatothegivendatabyusingany4differentsimilarityalgorithms.Nowyouhavetobuildamodelwhichcanfindthemostsimilardatatothegivendata.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-4.ImagineyouworkingasasalemanagernowyouneedtopredicttheRevenueandwhetherthatparticularrevenueisontheweekendornotandfindthe\\nInformational_DurationusingtheEnsemblelearningalgorithmDatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-5.Uberisataxiserviceproviderasweknow,weneedtopredictthehighbookingareausinganUnsuper visedalgorithmandpriceforthelocationusingasupervisedalgorithmandusesomemapfunctiontodisplaythedataDatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-6.ImagineyouhaveadatasetwhereyouhavepredictedloanEligibilityusingany4differentclassificationalgorithms.NowyouhavetobuildamodelwhichcanpredictloanEligibilityandyouneedtofindtheaccuracyofthemodelandbuilt-indockerandusesomelibrarytodisplaythatinfrontendDatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-7.ImagineyouhaveadatasetwhereyouneedtopredicttheGenresofMusic\\nusing\\nanUnsuper visedalgorithmandyouneedtofindtheaccuracyofthemodel,built-indocker,andusesomelibrarytodisplaythatinfrontendDatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-8.Quoraquestionpairsimilarity ,youneedtofindtheSimilaritybetweentwoquestionsbymappingthewordsinthequestionsusingTF-IDF,andusingasupervisedAlgorithmyouneedtofindthesimilaritybetweenthequestions.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-9.AcybersecurityagentwantstochecktheMicrosoftMalwaresoneedhecametoyouasaMachinelearningEngineeringwithData,YouneedtofindtheMalwareusingasupervisedalgorithmandyouneedtofindtheaccuracyofthemodel.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\n1.AnAd-Agencyanalyzedadatasetofonlineadsandusedamachinelearningmodeltopredictwhetherauserwouldclickonanadornot.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nAdvanceQUESTIONS:\\nQ-1.ASocialMediaInfluencercollecteddataonFacebookfriendrequestsandusedasupervisedalgorithmtopredictwhetherauserwouldacceptafriendrequestornot.DatasetThisistheDatasetYoucanusethisdatasetforthisquestion.Note:UseonlyDaskandUseMLflow\\nQ-2.Achemisthadtwochemicalflaskslabeled0and1whichconsistoftwodifferentchemicals.Heextracted3featuresfromthesechemicalsinordertodistinguishbetweenthem,youprovidedtheresultsderivedbythechemicalsandyourtaskistocreateamodelthatwilllabelchemical0or1givenitsthreefeaturesandbuilt-indockerandusesomelibrarytodisplaythatinfrontend.Note:Useonlypyspark\\nDatasetThisistheDatasetYoucanusethisdatasetforthisquestion.\\nQ-3.Acompanywantstopredictthesalesofitsproductbasedonthemoneyspentondifferentplatformsformarketing.Theywantyoutofigureouthowtheycanspendmoneyonmarketinginthefutureinsuchawaythattheycanincreasetheirprofitasmuchaspossiblebuilt-indockerandusesomelibrarytodisplaythatinfrontendDatasetThisistheDatasetYoucanusethisdatasetforthisquestion.Note:UseonlyDask\\nQ-4.Takeany3questionsanddeploythemtoAWSusingGitHubActionsandshowademolink\\nQ-5.Takeany3questionsanddeploythemtoAWSusingCircle-CIandshowademolinkDeepLearning\\nT o t a l\\nM a r k s :\\n1 0 0\\nE a c h\\nq u e s t i o n\\n2 0\\nm a r k s\\nQuestion1-Implemen t3differentCNNarchitectureswithacomparisontablefortheMNSITdatasetusingtheTensorflo wlibrary.Note-1.Themodelparametersforeacharchitectureshouldnotbemorethan8000parameters2.Codecommentsshouldbegivenforpropercodeunderstanding.3.Theminimumaccuracyforeachaccuracyshouldbeatleast96%\\nQuestion2-Implemen t5differentCNNarchitectureswithacomparisontableforCIFAR10datasetusingthePyTorchlibraryNote-1.Themodelparametersforeacharchitectureshouldnotbemorethan10000parameters\\n2Codecommentsshouldbegivenforpropercodeunderstanding\\nQuestion3-TrainaPureCNNwithlessthan10000trainableparametersusingtheMNISTDatasethavingminimumvalidationaccuracyof99.40%Note-1.Codecommentsshouldbegivenforpropercodeunderstanding.2.Implemen tinbothPyTorchandTensorflo wrespectiv ely\\nQuestion4-Designanend-to-endsolutionwithdiagramsforobjectdetectionusecasesleveragingAWScloudservicesandopen-sour cetechNote-1.YouneedtousebothAWScloudservicesandopen-sour cetechtodesigntheentiresolution2.Thepipelineshouldconsistofadatapipeline,mlpipeline,deploymentpipeline,andinferencepipeline.3.Inthedatapipeline,youwouldbedesigninghowtogetthedatafromexternalorexistingsourcesandtechusedforthesame4.Inthemlpipeline,youwouldbedesigninghowtotrainthemodel,andwhatallalgorithms,techniques,etc.wouldyoubeusing.Again,techusedforthesame5.Sincethisisadeeplearningproject,theuseofGPUs,andhoweffectivelyareyouusingthemtooptimizeforcostandtrainingtimeshouldalsobetakenintoconsideration.6.Inthedeploymentpipeline,youwouldbedesigninghoweffectivelyandefficientlyyouaredeployingthemodelinthecloud,7.Intheinferencepipeline,considerthecostofinferenceanditsoptimization\\nrelatedtocomputingresourcesandhandlingexternaltraffic8.Youcanuseanytooltodesignthearchitecture9.Domentiontheprosandconsofyourarchitectureandhowmuchfurtheritcanbeoptimizedanditstradeoffs.10.Doincludearetrainingapproachaswell.11.TrytoincludemanagedAWSresourcesfordeeplearninglikeAWSTextract,AWSSagemaker,etc.,andnotjustgeneral-purposecomputeresourceslikeS3,EC2,etc.Trytomixthebestofbothservices\\nQuestion5-\\nInQuestion4,youhavedesignedthearchitectureforanobjectdetectionusecaseleveragingAWSCloud,similarly ,hereyouwillbedesigningforDocumen tClassific ationusecaseleveragingAzureCloudservices.Note-1.MostofthepointsarethesameasinQuestion4,justcloudserviceswillchangeComput erVision\\nT o t a l\\nM a r k s :\\n2 0 0\\nE a c h\\nq u e s t i o n\\n2 0\\nm a r k s\\nQuestion1-Trainadeeplearningmodelwhichwouldclassifythevegetablesbasedontheimagesprovided.Thedatasetcanbeaccessedfromthegivenlink.\\nLink-https://www.kaggle.com/datasets/misrakahmed/v egetable-imag e-dataset\\nNote-1.UsePyTorchastheframeworkfortrainingmodel2.UseDistributedParallelTrainingtechniquetooptimizetrainingtime.3.Achieveanaccuracyofatleast85%onthevalidationdataset.4.Usealbumen tationslibraryforimagetransformation5.UseTensorBoar dloggingforvisualizingtrainingperformance6.UsecustommodularPythonscriptstotrainmodel7.OnlyJupyternotebookswillnotbeallowed8.Writecodecommentswhereverneededforunderstanding\\nQuestion2-FromQuestion1,youwouldgetatrainedmodelwhichwouldclassifythevegetablesbasedontheclasses.YouneedtoconvertthetrainedmodeltoONNXformatandachievefasterinferenceNote-1.Thereisnosetinferencetime,buttrytoachieveaslowaninferencetimeaspossible2.Createawebapptointeractwiththemodel,wheretheusercanuploadtheimageandgetpredictions3.Trytoreducethemodelsizeconsiderablysothatinferencetimecanbefaster4.UsemodularPythonscriptstotrainandinferthemodel5.OnlyJupyternotebookswillnotbeallowed6.WritecodecommentswheneverneededforunderstandingQuestion3-Scraptheimagesfrompopulare-commercewebsitesforvariousproductimagessoldonthosewebsites.Yourgoalistofetchtheimagesfromthewebsite,createcategoriesofdifferentproductclassesandtrainadeeplearningmodeltoclassifythesamebasedontheuserinput.Note-1.YoucanuseanyframeworkofyourchoicelikeTensorFlo worPyTorch2.Youhavetonotuseanypre-trainedmodel,butinsteadcreateyourowncustomarchitectureandthentrainthemodel.3.Writecodecommentswhereverneededforunderstanding4.Trytouselittlebigdatasetsothatmodelcanbegeneralized5.WritemodularPythonscriptstotrainandinferthemodel6.OnlyJupyterNotebookwillbenotallowed7.Writecodecommentswhereverneededforcodeunderstanding\\nQuestion4-YouhavetotrainacustomYOLOV7modelonthedatasetwhichislinkedbelow.Yourgoalistodetectdifferentproductsbasedonthegivenclassesbasedontheuserinput\\nLink-https://drive.google.com/file/d/1MEgD YJwO_PVVfAbyfjaRHXt7qoiBBHY t/view?usp=shar e_link\\nNote-1.YouhavetousePyTorchimplemen tationofYOLOV72.Thedatasetconsistsof102classeswithtrain,validation,andtestimagesalreadyintherespectiv efolders.3.Labelingisalreadydone,givenwiththedataset,soneedforannotation4.Sincethedatasetissmall,trytoachieveatleastanmAPof855.WritemodularPythonscriptstotrainthemodel6.WritecodecommentswhereverneededforunderstandingComputerVisionAssessmentiNeuron37.OnlyJupyterNotebookwillnotbeallowed\\nQuestion5-FromQuestion4,youwouldhaveacustom-trainedYOLOmodel.YourgoalistoneedtoconvertthemodeltoONNXformatandreducetheinferencetime.\\nNote-1.Reducetheinferencetimetoasmuchaspossible2.TrytoreducethemodelsizebyusingtechniqueslikeQuantization,etc3.Createawebappforuserstointeractwithyourmodelwhereuserscanuploadimagesandgetpredictions.4.WritemodularPythonscriptstoinferthemodel.5.OnlyJupyternotebooksarenotallowed.6.Writecodecommentswhereverneededforcodeunderstanding\\nQuestion6-Youhavetotrainacustomsegmen tationmodelbasedonDetectron2framework.Yourgoalistosegmen tthegivenimagesbasedontheuserinputintothedifferentclasses\\nLink-https://www.kaggle.com/competitions/open-imag es-2019-ins tance-segmen tation/data\\nNote-1.Forthis,onlytheJupyterNotebookisfine2.LabelsareinCOCOformat.3.Writecodecommentswhereverneededforunderstanding\\nQuestion7-FromQuestion6,youwouldhavecustomtrainedsegmen tationmodel.Yourgoalistoreducethemodelinferencetime\\nNote-1.Reduceinferencetimetoasmuchaspossible2.Createawebappforuserstointeractwithyourmodelwheretheycanuploadimagesandgetpredictions3.Writecodecommentswhereverneededforcodeunderstanding.\\nQuestion8-YouhavetotrainacustomobjectdetectionmodelbasedonDETR(DetectionTransformer)\\nLink-https://www.kaggle.com/datasets/andrewmvd/helme t-detection\\nNote-1.YouneedtouseHuggingFacePyTorchastheframework2.Thedatasetisaboutdetectingfootballplayersfromtheimagesprovided3.DataAnnotationsarealreadyinCOCOformat.4.WritecustomPythonscriptsfortraining.5.Writecodecommentswhereverneededforcodeunderstanding6.OnlyJupyterNotebooksarenotallowed\\nQuestion9-FromQuestion8,youwouldhaveacustomobjectdetectionmodelNote-1.Trytoreducethemodelsizeusingquantization2.Createawebappwheretheuserscaninteractwithyourmodel3.WritemodularPythonscriptformodelinference4.OnlyJupyterNotebooksarenotallowed5.Writecodecommentswhereverneededforcodeunderstanding\\nQuestion10-Fromallthequestionsfrom1to9,takeanyimageclassificationmodel,objectmodeldetectionmodel,andimagesegmen tationmodelanddeployitinthecloudNote-1.Deploymentofall3differentmodelsshouldbeAWS,Azure,andGCP2.Avideodemooftheapplicationworkinginthecloudshouldbegoodenough3.Containerizationofall3applicationsisimportantandshouldbepushedtoDockerHubComputerVisionAssessmentiNeuron54.CI-CDpipelinesusingGitHubactionsthatwoulddeploythemodelsinall3cloudsaremandatory.NaturalLanguag eProcessing\\nT o t a l\\nM a r k s :\\n2 0 0\\nE a c h\\nq u e s t i o n\\n2 0\\nm a r k s\\nQ-1.TakeanyYouTubevideoslinkandyourtaskistoextractthecommentsfromthatvideosandstoreitinacsvfileandthenyouneeddefinewhatismostdemandingtopicinthatvideoscommentsection.\\nQ-2.Takeanypdfandyourtaskistoextractthetextfromthatpdfandstoreitinacsvfileandthenyouneedtofindthemostrepeatedwordinthatpdf.\\nQ-3.fromquestion2,AsyougottheCSVandnowyouneedperformkeywordextractionfromthatcsvfileanddotheTopicmodeling\\nQ-4.TakeanytextfileandnowyourtaskistoTextSummariz ationwithoutusinghuggingtransformerlibrary\\nQ-5.Nowyouneedbuildyourownlanguag edetectionwiththefastTextmodelbyFacebookand\\nQ-6.GenerateresearchpaperstitlesusingBertmodelandcontainerizetheapplicationandpushtopublicdockerhub\\nQ-7.Nowyouneedtobuildyourownchatbotusingtheseq2seqmodelofAmazonwebsitebyscrapethewebsiteandcontainerizetheapplicationandpushtopublicdockerhub\\nQ-8.TakeaanyowndatasetandbuildaknowledgebotusingLlamamodel.\\nQ-9.Usingwisheryouneedtranscribeanyaudiofileandthenyouneedtoconvertthataudiofileintotextfileandnowconvertthattextfileintoaudiofileofdifferentlanguag e.\\nQ-10.BuildawholeEnd-EndapianddeployitonHeroku/railwayssothetaskisthatyouneedbuildaAuto-CorrectionoftextusingNLPNote:onlyJupyternotebookisnotallowedfrom5thquestion‚Üê\\nS u b m i s s i o n\\nP r o c e s s\\n‚Üí\\nThere\\nare\\nTwo\\nTypes\\nof\\nQuestions\\nTheory\\nbased\\nQuestion\\nand\\nProject-based\\n(where\\nyou\\nactually\\nhave\\nto\\ncode)\\nFirst\\nof\\nall,\\nYou\\nhave\\nto\\ncreate\\nan\\nGoogle\\ndoc,\\nwhere\\nyou\\nwill\\nadd\\nanswers\\nof\\nall\\nthe\\nquestions\\nIf\\nyou\\nare\\nattempting\\na\\nquestion\\nin\\nwhich\\nyou\\nhave\\nto\\nwrite\\ncode,\\nso\\ncreate\\na\\nrepo\\npush\\nyour\\ncode\\nto\\nrepo\\nand\\ncopy\\nthe\\nlink\\nof\\nrepo\\nand\\nadd\\nit\\ninto\\ndocs\\nas\\nshown\\nbelow\\nE g .\\nA n s w e r .\\n6\\nP y t h o n\\n-\\n>\\nG i t H u b\\nr e p o\\nl i n k\\nN o t e :\\n‚óè\\nI f\\ny o u\\na r e\\nb u i l d i n g\\na n y\\nE n d\\nt o\\ne n d\\np r o j e c t\\nt r y\\nt o\\nw r i t e\\nc o d e\\ni n\\n. p y\\nf i l e\\n‚óè\\nI f\\ny o u\\na r e\\no n l y\\na n a l y z i n g\\no r\\nd o i n g\\nE D A\\nu s e\\n. i p y n b\\nf i l e\\nIf\\nyou\\nare\\nattempting\\na\\ntheory-based\\nquestion\\nthen\\nyou\\nhave\\nto\\nadd\\nthe\\nanswer\\nin\\nthe\\nsame\\ngoogle\\ndocs\\nas\\nit\\'s\\nThen\\nsubmit\\nthat\\nfinal\\nlink\\n(google\\ndoc\\nlink\\nwhich\\nhas\\nall\\nthe\\nanswers)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most repeated word\n",
        "word_list = text.split()\n",
        "word_count = Counter(word_list)\n",
        "most_repeated_word, count = word_count.most_common(1)[0]"
      ],
      "metadata": {
        "id": "PRWfj4le0WNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the most repeated word and its count\n",
        "print(\"Most Repeated Word:\", most_repeated_word)\n",
        "print(\"Count:\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DxtOdOh0gHw",
        "outputId": "eaff801e-e018-4a67-963f-e1ceb7f5e29b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Repeated Word: the\n",
            "Count: 73\n"
          ]
        }
      ]
    }
  ]
}